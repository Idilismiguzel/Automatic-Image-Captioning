[//]: # (Image References)
[image1]: ./images/coco-examples.jpg "COCO"
[image2]: ./images/encoder-decoder.png "Encoder-Decoder"

# Automatic Image Captioning 

## Project Overview

This project requires to create a deep learning architecture with two components: a CNN to transform the input image into a set of features, an RNN that turns those features into descriptive text aka captions. Same as before, after completing the project it has to be submitted and reviewed by Udacity team.In this project, you will create a neural network architecture to automatically generate captions from images.

![image1]
![image2]

The project is broken up into a few main parts in four Python notebooks

__0_Dataset.ipynb__ : Loading and Visualizing Microsoft Common Objects in COntext (MS COCO) dataset to train the network

__1_Preliminaries.ipynb__ : Design a CNN-RNN model for automatically generating image captions.

__2_Training.ipynb__ : Train the CNN-RNN model.

__3_Inference.ipynb__ : Use your trained model to generate captions for images in the test dataset.
